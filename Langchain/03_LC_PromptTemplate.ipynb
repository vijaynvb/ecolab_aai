{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5WL5rwU6Esui",
      "metadata": {
        "id": "5WL5rwU6Esui"
      },
      "source": [
        "# **Prompts Template**\n",
        "\n",
        "\n",
        "A prompt template is a structured framework that allows for dynamic generation of prompts based on predefined patterns and placeholders. It typically includes fixed text and variables that can be filled with specific values at runtime. Prompt templates are useful when generating multiple prompts with similar structures but varying content or style.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_lEJ-VbxsSJx",
      "metadata": {
        "id": "_lEJ-VbxsSJx"
      },
      "source": [
        "Lets see an usecase how you can define a prompt template where you can configure values as placeholders and execute and pass it as a input to LLM\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u-jFZNEETIKO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-jFZNEETIKO",
        "outputId": "4cff341d-59b3-4b32-ae68-6a8e54e053ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.26-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.26-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.66)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.91.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.5.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.3.26-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.26-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-openai, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain-openai-0.3.26 langchain_community-0.3.26 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade langchain langchain_community langchain-openai\n",
        "!pip install --upgrade python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6e37738",
      "metadata": {
        "id": "d6e37738"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.getenv('OPENAI_API_VERSION')\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv('AZURE_OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "eb6c7d56",
      "metadata": {
        "id": "eb6c7d56"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    deployment_name=\"gpt-4o\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "FFxW9RQfFClE",
      "metadata": {
        "id": "FFxW9RQfFClE"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "Today is Monday, tomorrow is Wednesday.\n",
        "\n",
        "What is wrong with that statement?\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "eOqmPs0QkNct",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "eOqmPs0QkNct",
        "outputId": "70e3813d-f738-4ecb-9e61-98c3ad378c1f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The statement \"Today is Monday, tomorrow is Wednesday\" is incorrect because it skips Tuesday. The day that comes immediately after Monday is Tuesday, not Wednesday. \\n\\nIf today is Monday, tomorrow will be Tuesday, and the day after that will be Wednesday.'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = llm.invoke(prompt)\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oufRk-hOEpyK",
      "metadata": {
        "id": "oufRk-hOEpyK"
      },
      "source": [
        "## **Prompt template**\n",
        "\n",
        "An object that helps create prompts based on a combination of user input, other non-static information and a fixed template string.\n",
        "\n",
        "* **Template String**: A template string is defined, which includes placeholders for `style` and `text`. This template will be used to create dynamic prompts.\n",
        "* **ChatPromptTemplate**: The ChatPromptTemplate class from LangChain is used to create a prompt template from the defined string.\n",
        "* **Input Variables**: The input_variables attribute shows the placeholders that need to be filled when formatting the template."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "84ad2b93",
      "metadata": {
        "id": "84ad2b93"
      },
      "outputs": [],
      "source": [
        "template_string = \"\"\"Translate the text \\\n",
        "that is delimited by triple backticks \\\n",
        "into a style that is {style}. \\\n",
        "text: ```{text}```\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "c56d37f3",
      "metadata": {
        "id": "c56d37f3"
      },
      "outputs": [],
      "source": [
        "# prompt template\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "014cd73e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "014cd73e",
        "outputId": "2eb795a2-7b01-4d99-b72e-34e301580d56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['style', 'text'], input_types={}, partial_variables={}, template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n')"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_template.messages[0].prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "yBRDvJFgVelm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBRDvJFgVelm",
        "outputId": "94fe6d3e-ae45-4e48-86af-06f4014f6f5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['style', 'text']"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_template.messages[0].prompt.input_variables"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2F4JIbzmHGuE",
      "metadata": {
        "id": "2F4JIbzmHGuE"
      },
      "source": [
        "## **Formatting the Employee's Email**\n",
        "\n",
        "* **Employee Style**: A style specification for translating text is defined (British English in a calm and respectful tone).\n",
        "* **Employee Email**: A sample French email requesting vacation is provided.\n",
        "* **Format Messages**: The format_messages method of the prompt template is used to fill in the placeholders with the specified style and text.\n",
        "* Model Response: The formatted messages are sent to the language model for processing, and the response is printed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "c2af340f",
      "metadata": {
        "id": "c2af340f"
      },
      "outputs": [],
      "source": [
        "employee_style = \"\"\"British English \\\n",
        "in a calm and respectful tone\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "444891fb",
      "metadata": {
        "id": "444891fb"
      },
      "outputs": [],
      "source": [
        "# french language letter for vacation request\n",
        "employee_email = \"\"\"\n",
        "Objet : Demande de Congé\n",
        "\n",
        "Cher [Nom du Responsable],\n",
        "\n",
        "Je m'appelle John et je travaille au sein de la société XYZ.\n",
        "J'aimerais solliciter une demande de congé pour partir en vacances.\n",
        "Serait-il possible de discuter des dates qui conviendraient le mieux pour l'équipe et l'entreprise?\n",
        "\n",
        "Je vous remercie par avance pour votre compréhension et j'attends votre retour.\n",
        "\n",
        "Cordialement,\n",
        "John\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "f36b2801",
      "metadata": {
        "id": "f36b2801"
      },
      "outputs": [],
      "source": [
        "employee_messages = prompt_template.format_messages(\n",
        "                    style=employee_style,\n",
        "                    text=employee_email)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "a4dc09e3",
      "metadata": {
        "id": "a4dc09e3"
      },
      "outputs": [],
      "source": [
        "employee_response = llm(employee_messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "c93c6be1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "collapsed": true,
        "id": "c93c6be1",
        "outputId": "d932cc29-1397-4429-dc6b-9cee4ba63be6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Subject: Request for Leave  \\n\\nDear [Manager’s Name],  \\n\\nI trust this message finds you well. My name is John, and I am a member of the team at XYZ.  \\n\\nI am writing to kindly request leave in order to take a holiday. I was wondering if it would be possible for us to discuss suitable dates that would work best for both the team and the company.  \\n\\nThank you in advance for your understanding. I look forward to hearing from you.  \\n\\nYours sincerely,  \\nJohn  '"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "employee_response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NMdWIvLXHhcM",
      "metadata": {
        "id": "NMdWIvLXHhcM"
      },
      "source": [
        "## **Formatting the Manager's Reply**\n",
        "\n",
        "* **Manager Reply**: A sample reply from a manager is provided in English.\n",
        "* **Manager Style**: The style for translating the manager's reply is defined (a polite tone that speaks in French).\n",
        "* **Format Messages**: The prompt template is used again to format the manager's reply with the specified style.\n",
        "* **Model Response**: The formatted messages are sent to the model, and the response is printed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "f65a0f80",
      "metadata": {
        "id": "f65a0f80"
      },
      "outputs": [],
      "source": [
        "manager_reply = \"\"\"\n",
        "Subject: Re: Demande de Congé\n",
        "\n",
        "Hi John,\n",
        "\n",
        "Thank you for reaching out. I've reviewed your request for vacation leave.\\\n",
        "Please provide the specific dates you'd like to take off, so we can ensure proper coverage during your absence.\n",
        "\n",
        "Looking forward to your response.\n",
        "\n",
        "Best regards,\n",
        "[Manager's Name]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "516c5695",
      "metadata": {
        "id": "516c5695"
      },
      "outputs": [],
      "source": [
        "manager_style_pirate = \"\"\"\\\n",
        "a polite tone \\\n",
        "that speaks in French\\\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "9befdb87",
      "metadata": {
        "id": "9befdb87"
      },
      "outputs": [],
      "source": [
        "manager_messages = prompt_template.format_messages(\n",
        "    style=manager_style_pirate,\n",
        "    text=manager_reply)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "fb694b8f",
      "metadata": {
        "id": "fb694b8f"
      },
      "outputs": [],
      "source": [
        "manager_response = llm.invoke(manager_messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "967aede3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "967aede3",
        "outputId": "ddcf8153-4b2e-493d-ae05-98dd9fed9144",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Objet : Réponse à votre demande de congé  \\n\\nBonjour John,  \\n\\nJe vous remercie de m’avoir contacté. J’ai bien pris connaissance de votre demande de congé. Pourriez-vous, s’il vous plaît, préciser les dates exactes auxquelles vous souhaiteriez vous absenter ? Cela nous permettra d’organiser une couverture adéquate pendant votre absence.  \\n\\nDans l’attente de votre retour, je reste à votre disposition pour toute question.  \\n\\nCordialement,  \\n[Nom du Responsable]  '"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "manager_response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UOHUsUjvJ_Xm",
      "metadata": {
        "id": "UOHUsUjvJ_Xm"
      },
      "source": [
        "# **Let's Do an Activity**\n",
        "\n",
        "## **Objective**\n",
        "\n",
        "Practice creating and utilizing a prompt template to generate customized prompts for a language model.\n",
        "\n",
        "## **Steps**\n",
        "\n",
        "* Define a Template String\n",
        "* Instantiate a Prompt Template\n",
        "* Prepare Variables\n",
        "* Format Messages\n",
        "* Interact with a Language Model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
