{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZDsOC8WZx24"
      },
      "source": [
        "# **Retrival**\n",
        "\n",
        "In LangChain, retrieval refers to the process of accessing and fetching relevant pieces of information from a collection of documents or data sources based on a query. This involves using techniques like similarity search and embedding-based methods to find and return the most pertinent documents or text segments that match the query's context and content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyhmxkE1YbWo"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# update or install the necessary libraries\n",
        "!pip install --upgrade langchain langchain_community langchain-openai\n",
        "!pip install pypdf\n",
        "!pip install tiktoken\n",
        "!pip install faiss-cpu\n",
        "!pip install lark\n",
        "!pip install --upgrade python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmhrM0gQohMS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.getenv('OPENAI_API_VERSION')\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv('AZURE_OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD-yLJRYYkgW"
      },
      "source": [
        "# **Vectorstore retrieval**\n",
        "\n",
        "Vectorstore retrieval is a technique that involves storing and retrieving data using vector representations of text. It enables efficient similarity searches by converting text into high-dimensional vectors and then finding the closest vectors in the database. This method is particularly useful for applications requiring fast and accurate information retrieval based on semantic similarity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDKCuVkvbmFZ"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load PDF\n",
        "loaders = [\n",
        "    # Duplicate documents on purpose - messy data\n",
        "    PyPDFLoader(\"./content/MachineLearning-Lecture01.pdf\"),\n",
        "    PyPDFLoader(\"./content/MachineLearning-Lecture02.pdf\"),\n",
        "    PyPDFLoader(\"./content/MachineLearning-Lecture03.pdf\")\n",
        "\n",
        "]\n",
        "docs = []\n",
        "for loader in loaders:\n",
        "    docs.extend(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZdCG2EYbnD6",
        "outputId": "907e3f49-e5e8-49de-f5c3-6f5040068a40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "151"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap = 150\n",
        ")\n",
        "\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "len(splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojzmOu7OoyNm"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "persist_directory = 'docs/faiss/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja6dCyY1pEGQ",
        "outputId": "13d5cc1d-ff6e-4cb8-f912-4eac6de552af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "\n",
        "# Initialize Azure OpenAI embeddings\n",
        "embedding = AzureOpenAIEmbeddings(azure_deployment=\"text-embedding-ada-002\")\n",
        "\n",
        "# !rm -rf ./docs/faiss  # remove old database files if any\n",
        "vectordb = FAISS.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding\n",
        ")\n",
        "\n",
        "vectordb.save_local(persist_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H22zqjeWpYef",
        "outputId": "9076f079-b5ce-4f9d-adf4-3f45299b1e5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "151"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectordb._collection.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "I-SK9rxSpc2V"
      },
      "outputs": [],
      "source": [
        "texts = [\n",
        "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
        "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
        "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALEQTlhCpgV_",
        "outputId": "9932613e-4d34-492c-c0dd-d59286e5cab5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        }
      ],
      "source": [
        "smalldb = FAISS.from_texts(texts, embedding=embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5M6a4hE3pgqO"
      },
      "outputs": [],
      "source": [
        "question = \"Tell me about all-white mushrooms with large fruiting bodies\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVd3L-5sYpln"
      },
      "source": [
        "# **Similarity Search**\n",
        "\n",
        "Similarity search is a method used to find items in a database that are most similar to a given query item based on certain criteria. It involves comparing vector representations of items and retrieving those with the smallest distance or highest similarity score. This approach is commonly used in applications like document retrieval, image matching, and recommendation systems.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAydVLibpgu1",
        "outputId": "a0509b5a-19a3-4566-9f1b-9a004ab2dcca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
              " Document(metadata={}, page_content='The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).')]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectordb.similarity_search(question, k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gztlWTUsp3Iz",
        "outputId": "952938ba-b743-45b1-c257-0a0134029321"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
              " Document(metadata={}, page_content='A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.')]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectordb.max_marginal_relevance_search(question,k=2, fetch_k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw97_yj2aili"
      },
      "source": [
        "## Addressing Diversity: Maximum marginal relevance\n",
        "\n",
        "Last class we introduced one problem: how to enforce diversity in the search results.\n",
        "\n",
        "`Maximum marginal relevance` strives to achieve both relevance to the query *and diversity* among the results.\n",
        "\n",
        "Maximum Marginal Relevance (MMR) is a technique used in information retrieval to enhance the diversity of search results. It aims to select documents that are not only relevant to a query but also diverse from each other. This diversity helps provide a broader perspective or coverage of the topic being queried.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIecO_wsZui6",
        "outputId": "cf83ad14-ac52-4ee1-8759-a049e6736e96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        }
      ],
      "source": [
        "question = \"what did they say about matlab?\"\n",
        "docs_ss = vectordb.similarity_search(question,k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nlK1SP4aaqcG",
        "outputId": "fe569076-e572-4c0d-9461-89bec9a65e54"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people c'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_ss[0].page_content[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "j-9TE7-_asd1",
        "outputId": "9f5018fb-bd68-44dd-b22b-88c1996dbe3b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'into his office and he said, \"Oh, professor, professor, thank you so much for your \\nmachine learning'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_ss[1].page_content[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4C--BrRcnJJ"
      },
      "source": [
        "Note the difference in results with `MMR`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pFsLht7Ucmbx"
      },
      "outputs": [],
      "source": [
        "docs_mmr = vectordb.max_marginal_relevance_search(question,k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vtbK71DucqzB",
        "outputId": "688202b1-b0f2-46bc-de15-9321172ce3cc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people c'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_mmr[0].page_content[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4Cmv6V5ucr_1",
        "outputId": "9aba5702-367c-4f4c-bdb0-d05009b1fa3d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'least squares regression being a bad idea for classification problems and then I did a \\nbunch of mat'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_mmr[1].page_content[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bIQyJjqcyGo"
      },
      "source": [
        "## **Addressing Specificity: working with metadata**\n",
        "\n",
        "In last lecture, we showed that a question about the third lecture can include results from other lectures as well.\n",
        "\n",
        "To address this, many vectorstores support operations on `metadata`.\n",
        "\n",
        "`metadata` provides context for each embedded chunk.\n",
        "\n",
        "Metadata filtering refers to the process of selectively retrieving or excluding data based on predefined metadata attributes or criteria. In the context of information retrieval systems like LangChain, metadata filtering allows users to narrow down search results by specifying metadata tags or attributes associated with documents or data chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "OyCYTYboctXP"
      },
      "outputs": [],
      "source": [
        "question = \"what did they say about regression in the third lecture?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jnW9VfKJc2Uz"
      },
      "outputs": [],
      "source": [
        "docs = vectordb.similarity_search(\n",
        "    question,\n",
        "    k=3,\n",
        "    filter={\"source\":\"docs/cs229_lectures/MachineLearning-Lecture03.pdf\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HMESrO2Zc3jk"
      },
      "outputs": [],
      "source": [
        "for d in docs:\n",
        "    d.metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZpSertVc_mi"
      },
      "source": [
        "## **Addressing Specificity: working with metadata using self-query retriever**\n",
        "\n",
        "But we have an interesting challenge: we often want to infer the metadata from the query itself.\n",
        "\n",
        "To address this, we can use `SelfQueryRetriever`, which uses an LLM to extract:\n",
        "\n",
        "1. The `query` string to use for vector search\n",
        "2. A metadata filter to pass in as well\n",
        "\n",
        "Most vector databases support metadata filters, so this doesn't require any new databases or indexes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "daIJI8cSc48Z"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "from langchain.chains.query_constructor.base import AttributeInfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1mgSnmYidDWN"
      },
      "outputs": [],
      "source": [
        "metadata_field_info = [\n",
        "    AttributeInfo(\n",
        "        name=\"source\",\n",
        "        description=\"The lecture the chunk is from, should be one of `docs/cs229_lectures/MachineLearning-Lecture01.pdf`, `docs/cs229_lectures/MachineLearning-Lecture02.pdf`, or `docs/cs229_lectures/MachineLearning-Lecture03.pdf`\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"page\",\n",
        "        description=\"The page from the lecture\",\n",
        "        type=\"integer\",\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "NUov2iPZdF_J"
      },
      "outputs": [],
      "source": [
        "document_content_description = \"Lecture notes\"\n",
        "llm = AzureChatOpenAI(deployment_name=\"gpt-4o\")\n",
        "retriever = SelfQueryRetriever.from_llm(\n",
        "    llm,\n",
        "    vectordb,\n",
        "    document_content_description,\n",
        "    metadata_field_info,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "UXHu75E_dLRx"
      },
      "outputs": [],
      "source": [
        "question = \"what did they say about regression in the third lecture?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBlr6jzNda58"
      },
      "source": [
        "**You will receive a warning** about predict_and_parse being deprecated the first time you executing the next line. This can be safely ignored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "8Sdl8kDRdaVf"
      },
      "outputs": [],
      "source": [
        "docs = retriever.invoke(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "3r6AeRp5ddtO"
      },
      "outputs": [],
      "source": [
        "for d in docs:\n",
        "    d.metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TjRj-23dzcX"
      },
      "source": [
        "## **Additional tricks: compression**\n",
        "\n",
        "Another approach for improving the quality of retrieved docs is compression.\n",
        "\n",
        "Information most relevant to a query may be buried in a document with a lot of irrelevant text.\n",
        "\n",
        "Passing that full document through your application can lead to more expensive LLM calls and poorer responses.\n",
        "\n",
        "Contextual compression is meant to fix this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "vdWqgzQUdgD2"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-EeUfJS_d2Ok"
      },
      "outputs": [],
      "source": [
        "def pretty_print_docs(docs):\n",
        "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1LIo3aO9d3T9"
      },
      "outputs": [],
      "source": [
        "# Wrap our vectorstore\n",
        "llm = AzureChatOpenAI(deployment_name=\"gpt-4o\")\n",
        "compressor = LLMChainExtractor.from_llm(llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "4U8aNmNTd7MV"
      },
      "outputs": [],
      "source": [
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=vectordb.as_retriever()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyAK28F2d8ja",
        "outputId": "7a44b8ff-ab9c-4bd2-ef57-399c9c984743"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document 1:\n",
            "\n",
            "those homeworks will be done in either MATLAB or in Octave, which is sort of — I  \n",
            "know some people call it a free version of MATLAB, which it sort of is, sort of isn't.  \n",
            "So I guess for those of you that haven't seen MATLAB before, and I know most of you  \n",
            "have, MATLAB is I guess part of the programming language that makes it very easy to  \n",
            "write codes using matrices, to write code for numerical routines, to move data around, to  \n",
            "plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of  \n",
            "learning algorithms.  \n",
            "And in case some of you want to work on your own home computer or something if you  \n",
            "don't have a MATLAB license, for the purposes of this class, there's also — [inaudible]  \n",
            "write that down [inaudible] MATLAB — there's also a software package called Octave  \n",
            "that you can download for free off the Internet. And it has somewhat fewer features than  \n",
            "MATLAB, but it's free, and for the purposes of this class, it will work for just about  \n",
            "everything.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            "\"Oh, it was the MATLAB.\"  \n",
            "So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard,  \n",
            "and we'll actually have a short MATLAB tutorial in one of the discussion sections for  \n",
            "those of you that don't know it.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "\n",
            "So all the homeworks can be done in MATLAB or Octave, and let's see.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 4:\n",
            "\n",
            "I think MATLAB is actually totally worth learning. I know R and MATLAB, and I personally end up using MATLAB quite a bit more often for various reasons.\n"
          ]
        }
      ],
      "source": [
        "question = \"what did they say about matlab?\"\n",
        "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
        "pretty_print_docs(compressed_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsmkyBr6eBpd"
      },
      "source": [
        "# **Combining various techniques**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CDG99iTd9k7"
      },
      "outputs": [],
      "source": [
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5n6DowTeFVs",
        "outputId": "98c50318-7640-4d2f-c912-ab21a3aeea12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document 1:\n",
            "\n",
            "those homeworks will be done in either MATLAB or in Octave, which is sort of — I  \n",
            "know some people call it a free version of MATLAB, which it sort of is, sort of isn't.  \n",
            "So I guess for those of you that haven't seen MATLAB before, and I know most of you  \n",
            "have, MATLAB is I guess part of the programming language that makes it very easy to  \n",
            "write codes using matrices, to write code for numerical routines, to move data around, to  \n",
            "plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of  \n",
            "learning algorithms.  \n",
            "And in case some of you want to work on your own home computer or something if you  \n",
            "don't have a MATLAB license, for the purposes of this class, there's also — [inaudible]  \n",
            "write that down [inaudible] MATLAB — there' s also a software package called Octave  \n",
            "that you can download for free off the Internet. And it has somewhat fewer features than  \n",
            "MATLAB, but it's free, and for the purposes of this class, it will work for just about  \n",
            "everything.  \n",
            "So actually I, well, so yeah, just a side comment for those of you that haven't seen  \n",
            "MATLAB before I guess, once a colleague of mine at a different university, not at  \n",
            "Stanford, actually teaches another machine learning course. He's taught it for many years.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            ">>>\n",
            "And the student said, \"Oh, it was the MATLAB.\"  \n",
            "So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, \n",
            "and we'll actually have a short MATLAB tutorial in one of the discussion sections for \n",
            "those of you that don't know it.  \n",
            ">>>\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "\n",
            "So all the homeworks can be done in MATLAB or Octave.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 4:\n",
            "\n",
            "Oh, yeah, let's see, right. So our policy has been that you're welcome to use R, but I would strongly advise against it, mainly because in the last problem set, we actually supply some code that will run in Octave but that would be somewhat painful for you to translate into R yourself. So for your other assignments, if you wanna submit a solution in R, that's fine. But I think MATLAB is actually totally worth learning. I know R and MATLAB, and I personally end up using MATLAB quite a bit more often for various reasons.\n"
          ]
        }
      ],
      "source": [
        "question = \"what did they say about matlab?\"\n",
        "compressed_docs = compression_retriever.invoke(question)\n",
        "pretty_print_docs(compressed_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyR-CLONeJ3J"
      },
      "source": [
        "# **Other types of retrieval**\n",
        "\n",
        "It's worth noting that vectordb as not the only kind of tool to retrieve documents.\n",
        "\n",
        "The `LangChain` retriever abstraction includes other ways to retrieve documents, such as TF-IDF or SVM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "YGnmxnyDeGnR"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import SVMRetriever\n",
        "from langchain.retrievers import TFIDFRetriever\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "RAAwmUazeMoN"
      },
      "outputs": [],
      "source": [
        "# Load PDF\n",
        "loader = PyPDFLoader(\"/content/MachineLearning-Lecture01.pdf\")\n",
        "pages = loader.load()\n",
        "all_page_text=[p.page_content for p in pages]\n",
        "joined_page_text=\" \".join(all_page_text)\n",
        "\n",
        "# Split\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
        "splits = text_splitter.split_text(joined_page_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "iT2vMH8peQrN"
      },
      "outputs": [],
      "source": [
        "# Retrieve\n",
        "svm_retriever = SVMRetriever.from_texts(splits,embedding)\n",
        "tfidf_retriever = TFIDFRetriever.from_texts(splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS386Lk6eSpN",
        "outputId": "9c470739-e6fa-453f-9a20-87599dc90c0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={}, page_content=\"Testing, testing. Okay, cool. Thanks. So all right, online resources. The class has a home page, so it's in on the handouts. I \\nwon't write on the chalkboard — http:// cs229.stanford.edu. And so when there are \\nhomework assignments or things like that, we usually won't sort of — in the mission of \\nsaving trees, we will usually not give out many handouts in class. So homework \\nassignments, homework solutions will be posted online at the course home page.  \\nAs far as this class, I've also written, and I guess I've also revised every year a set of \\nfairly detailed lecture notes that cover the technical content of this class. And so if you \\nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \\nall the math and equations and so on that I'll be doing in class.  \\nThere's also a newsgroup, su.class.cs229, also written on the handout. This is a \\nnewsgroup that's sort of a forum for people in the class to get to know each other and \\nhave whatever discussions you want to have amongst yourselves. So the class newsgroup \\nwill not be monitored by the TAs and me. But this is a place for you to form study groups \\nor find project partners or discuss homework problems and so on, and it's not monitored \\nby the TAs and me. So feel free to talk trash about this class there.  \\nIf you want to contact the teaching staff, please use the email address written down here, \\ncs229-qa@cs.stanford.edu. This goes to an account that's read by all the TAs and me. So\")"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"What are major topics for this class?\"\n",
        "docs_svm=svm_retriever.invoke(question)\n",
        "docs_svm[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BI9uxgteUZx",
        "outputId": "20d25b56-f192-4df1-9637-bd765f535b60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={}, page_content=\"yourselves. You can also come and talk to me or the TAs if you want to brainstorm ideas \\nwith us.  \\nOkay. So one more organizational question. I'm curious, how many of you know \\nMATLAB? Wow, cool, quite a lot. Okay. So as part of the — act ually how many of you \\nknow Octave or have used Octave? Oh, okay, much smaller number.  \\nSo as part of this class, especially in the homeworks, we'll ask you to implement a few \\nprograms, a few machine learning algorithms as part of the homeworks. And most of those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people call it a free version of MATLAB, which it sort of is, sort of isn't.  \\nSo I guess for those of you that haven't seen MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to \\nwrite codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your own home computer or something if you \\ndon't have a MATLAB license, for the purposes of this class, there's also — [inaudible] \\nwrite that down [inaudible] MATLAB — there' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than \\nMATLAB, but it's free, and for the purposes of this class, it will work for just about \\neverything.\")"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"what did they say about matlab?\"\n",
        "docs_tfidf=tfidf_retriever.invoke(question)\n",
        "docs_tfidf[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRmZkqrCe0hg"
      },
      "source": [
        "# **Let's Do an Activity**\n",
        "\n",
        "## **Objective**\n",
        "\n",
        "Explore different retrieval techniques in LangChain to fetch relevant documents based on queries.\n",
        "\n",
        "## **Scenario**\n",
        "\n",
        "You are building a document retrieval system for a research library. This activity will help you understand and implement various retrieval methods to efficiently fetch documents related to specific topics or queries.\n",
        "\n",
        "## **Steps**\n",
        "\n",
        "* Load Documents\n",
        "* Embedding and Vector Store\n",
        "* Similarity Search\n",
        "* Maximum Marginal Relevance (MMR)\n",
        "* Metadata Filtering\n",
        "* Alternative Retrieval Methods"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
