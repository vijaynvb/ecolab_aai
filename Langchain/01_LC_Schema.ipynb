{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sKJOkJ8ymIu"
      },
      "source": [
        "# **Schema**\n",
        "- Nuts and Bolts of working with Large Language Models (LLMs)\n",
        "\n",
        "**Problem Statement**\n",
        "- Design and implement a schema for interacting with Large Language Models (LLMs) that ensures consistent, structured, and efficient communication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KUU7dHAy40b"
      },
      "source": [
        "## **Text**\n",
        "- The natural language way to interact with LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFFpbfTezUXu"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# update or install the necessary libraries\n",
        "!pip install --upgrade langchain langchain_community langchain-openai\n",
        "!pip install --upgrade python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PN-Tn7S-zRtO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.getenv('OPENAI_API_VERSION')\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv('AZURE_OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CjJN2uNAy7zP",
        "outputId": "8ff2549e-f44b-426a-fb3b-1c3fb19e37de"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'What day comes after Friday?'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You'll be working with simple strings as prompts(that'll soon grow in complexity!)\n",
        "my_text = \"What day comes after Friday?\"\n",
        "my_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ROZyFauUkh1U",
        "outputId": "b60190ac-6455-4f52-c29c-177cad05ba94"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The day that comes after Friday is **Saturday**.'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    deployment_name=\"gpt-4o\",\n",
        "    )\n",
        "\n",
        "response = llm.invoke(my_text)\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAtXSeHiyysP"
      },
      "source": [
        "## **Chat Messages**\n",
        "Like text, but specified with a message type (System, Human, AI)\n",
        "\n",
        "* **System** - Helpful background context that tell the AI what to do\n",
        "* **Human** - Messages that are intented to represent the user\n",
        "* **AI** - Messages that show what the AI responded with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qQMBQ1eOy1DR"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "# This it the language model we'll use. We'll talk about what we're doing below in the next section\n",
        "chat = AzureChatOpenAI(deployment_name=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZMOJ-3U0y-Y"
      },
      "source": [
        "Now let's create a few messages that simulate a chat experience with a bot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SCNi-wrj0hsF",
        "outputId": "79779aad-1ffc-4528-cd32-975bc99d2160"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'How about a fresh Caprese salad with tomatoes, mozzarella, basil, and a drizzle of olive oil?'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chat.invoke(\n",
        "    [\n",
        "        SystemMessage(content=\"You are a nice AI bot that helps a user figure out what to eat in one short sentence\"),\n",
        "        HumanMessage(content=\"I like tomatoes, what should I eat?\")\n",
        "    ]\n",
        ")\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGkM6TjsGRNz"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HZ6pJr51JVS"
      },
      "source": [
        "\n",
        "You can also pass more chat history w/ responses from the AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IG_MQHiz02Gf",
        "outputId": "23977a34-c3e2-4dbe-c916-18b126aef374"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Explore the Promenade des Anglais, enjoy fresh seafood at local restaurants, visit the colorful Old Town (Vieux Nice), and take in stunning views from Castle Hill.'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chat.invoke(\n",
        "    [\n",
        "        SystemMessage(content=\"You are a nice AI bot that helps a user figure out where to travel in one short sentence\"),\n",
        "        HumanMessage(content=\"I like the beaches where should I go?\"),\n",
        "        AIMessage(content=\"You should go to Nice, France\"),\n",
        "        HumanMessage(content=\"What else should I do when I'm there?\")\n",
        "    ]\n",
        ")\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfkytXMI1M4A"
      },
      "source": [
        "You can also exclude the system message if you want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xNJqFOUo1LbX",
        "outputId": "2f26ab21-2b5a-4ca2-847d-08742e9615ce"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The day that comes after Thursday is **Friday**.'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chat.invoke(\n",
        "    [\n",
        "        HumanMessage(content=\"What day comes after Thursday?\")\n",
        "    ]\n",
        ")\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjWPkWmQ1Wt8"
      },
      "source": [
        "## **Documents**\n",
        "An object that holds a piece of text and metadata (more information about that text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "toEl31Pa1QO2"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import Document\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "# This it the language model we'll use. We'll talk about what we're doing below in the next section\n",
        "chat = AzureChatOpenAI(deployment_name=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qcwHNuao1aZW"
      },
      "outputs": [],
      "source": [
        "document = Document(page_content=\"This is my document. It is full of text that I've gathered from other places\",\n",
        "         metadata={\n",
        "             'my_document_id' : 234234,\n",
        "             'my_document_source' : \"The LangChain Papers\",\n",
        "             'my_document_create_time' : 1680013019\n",
        "         })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Z-0Gd4KXoUz3"
      },
      "outputs": [],
      "source": [
        "# Prepare the prompt by combining the document content with your custom prompt\n",
        "prompt = f\"Document Content: {document.page_content}\\n\\nPlease summarize the above document.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1vTNnNX3oZjm",
        "outputId": "930a7057-2be4-4fe6-8d63-b6a9942ef61a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The document is a collection of text sourced from various places.'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the response from the language model\n",
        "response = chat.invoke(prompt)\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGXfmlSV1irM"
      },
      "source": [
        "But you don't have to include metadata if you don't want to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WLVasVVM1ceF"
      },
      "outputs": [],
      "source": [
        "document1 = Document(page_content=\"This is my document. It is full of text that I've gathered from other places\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8nRGsnjmos-1"
      },
      "outputs": [],
      "source": [
        "# Prepare the prompt by combining the document content with your custom prompt\n",
        "prompt1 = f\"Document Content: {document1.page_content}\\n\\nPlease summarize the above document.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "i_4SDqdso1Be",
        "outputId": "c4dc8ca3-af9c-46cc-fd7c-9cd3bb81fd97"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The document contains text that the author has collected from various sources.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the response from the language model\n",
        "response = chat.invoke(prompt1)\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-CQSoQo34GT"
      },
      "source": [
        "# **Let's Do an Activity**\n",
        "\n",
        "Create a simple interaction using LangChain and OpenAI's API. Define system, human, and AI messages to simulate a conversation with a travel recommendation bot. Additionally, create a document schema to store information about travel destinations.\n",
        "\n",
        "**Steps**\n",
        "\n",
        "* **Set Up**: Install the necessary libraries and set up your OpenAI API key.\n",
        "* **Define Messages**: Create system, human, and AI messages for a travel bot.\n",
        "* **Simulate Interaction**: Use the chat function to simulate a conversation.\n",
        "* **`Create Document`**: Define a document schema to store information about a travel destination."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft0J5cTOBeqY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
