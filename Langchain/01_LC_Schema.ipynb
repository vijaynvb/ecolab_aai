{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sKJOkJ8ymIu"
      },
      "source": [
        "# **Schema**\n",
        "- Nuts and Bolts of working with Large Language Models (LLMs)\n",
        "\n",
        "**Problem Statement**\n",
        "- Design and implement a schema for interacting with Large Language Models (LLMs) that ensures consistent, structured, and efficient communication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KUU7dHAy40b"
      },
      "source": [
        "## **Text**\n",
        "- The natural language way to interact with LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mFFpbfTezUXu"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# update or install the necessary libraries\n",
        "!pip install --upgrade langchain langchain_community langchain-openai\n",
        "!pip install --upgrade python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PN-Tn7S-zRtO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.getenv('OPENAI_API_VERSION')\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv('AZURE_OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CjJN2uNAy7zP",
        "outputId": "8ff2549e-f44b-426a-fb3b-1c3fb19e37de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'till when were you trained?'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You'll be working with simple strings as prompts(that'll soon grow in complexity!)\n",
        "my_text = \"till when were you trained?\"\n",
        "my_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ROZyFauUkh1U",
        "outputId": "b60190ac-6455-4f52-c29c-177cad05ba94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I was last trained on information up until **October 2023**. Let me know how I can assist you!'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    deployment_name=\"gpt-4o\",\n",
        "    )\n",
        "\n",
        "response = llm.invoke(my_text)\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAtXSeHiyysP"
      },
      "source": [
        "## **Chat Messages**\n",
        "Like text, but specified with a message type (System, Human, AI)\n",
        "\n",
        "* **System** - Helpful background context that tell the AI what to do\n",
        "* **Human** - Messages that are intented to represent the user\n",
        "* **AI** - Messages that show what the AI responded with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qQMBQ1eOy1DR"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "# This it the language model we'll use. We'll talk about what we're doing below in the next section\n",
        "chat = AzureChatOpenAI(deployment_name=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZMOJ-3U0y-Y"
      },
      "source": [
        "Now let's create a few messages that simulate a chat experience with a bot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SCNi-wrj0hsF",
        "outputId": "79779aad-1ffc-4528-cd32-975bc99d2160"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='How about a fresh tomato caprese salad with mozzarella, basil, and a drizzle of balsamic glaze?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 39, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-C6DuRlamZYF73sO7rSEBmLfki3qiK', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'detected': False, 'filtered': False}, 'protected_material_text': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run--9b65616f-058f-4f45-887b-cbf61cd8cd42-0', usage_metadata={'input_tokens': 39, 'output_tokens': 22, 'total_tokens': 61, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chat.invoke(\n",
        "    [\n",
        "        SystemMessage(content=\"You are a nice AI bot that helps a user figure out what to eat in one short sentence\"),\n",
        "        HumanMessage(content=\"I like tomatoes, what should I eat?\")\n",
        "    ]\n",
        ")\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGkM6TjsGRNz"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HZ6pJr51JVS"
      },
      "source": [
        "\n",
        "You can also pass more chat history w/ responses from the AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IG_MQHiz02Gf",
        "outputId": "23977a34-c3e2-4dbe-c916-18b126aef374"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In Nice, you can relax on the pebble beaches, savor local specialties like Socca at bustling markets, take a day trip to nearby coastal towns like Èze or Antibes, and enjoy the vibrant nightlife along the Côte d'Azur!\""
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chat.invoke(\n",
        "    [\n",
        "        SystemMessage(content=\"You are a nice AI bot that helps a user figure out where to travel in one short sentence\"),\n",
        "        HumanMessage(content=\"I like the beaches where should I go?\"),\n",
        "        AIMessage(content=response.content),\n",
        "        HumanMessage(content=\"What else should I do when I'm there?\")\n",
        "    ]\n",
        ")\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfkytXMI1M4A"
      },
      "source": [
        "You can also exclude the system message if you want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xNJqFOUo1LbX",
        "outputId": "2f26ab21-2b5a-4ca2-847d-08742e9615ce"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The day that comes after Thursday is **Friday**.'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chat.invoke(\n",
        "    [\n",
        "        HumanMessage(content=\"What day comes after Thursday?\")\n",
        "    ]\n",
        ")\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjWPkWmQ1Wt8"
      },
      "source": [
        "## **Documents**\n",
        "An object that holds a piece of text and metadata (more information about that text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "toEl31Pa1QO2"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import Document\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "# This it the language model we'll use. We'll talk about what we're doing below in the next section\n",
        "chat = AzureChatOpenAI(deployment_name=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qcwHNuao1aZW"
      },
      "outputs": [],
      "source": [
        "document = Document(page_content=\"This is my document. It is full of text that I've gathered from other places\",\n",
        "         metadata={\n",
        "             'my_document_id' : 234234,\n",
        "             'my_document_source' : \"The LangChain Papers\",\n",
        "             'my_document_create_time' : 1680013019\n",
        "         })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'my_document_id': 234234, 'my_document_source': 'The LangChain Papers', 'my_document_create_time': 1680013019}, page_content=\"This is my document. It is full of text that I've gathered from other places\")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Z-0Gd4KXoUz3"
      },
      "outputs": [],
      "source": [
        "# Prepare the prompt by combining the document content with your custom prompt\n",
        "prompt = f\"Document Content: {document.page_content}\\n\\nPlease summarize the above document.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Document Content: This is my document. It is full of text that I've gathered from other places\\n\\nPlease summarize the above document.\""
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1vTNnNX3oZjm",
        "outputId": "930a7057-2be4-4fe6-8d63-b6a9942ef61a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The document is a collection of text sourced from various places.'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the response from the language model\n",
        "response = chat.invoke(prompt)\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGXfmlSV1irM"
      },
      "source": [
        "But you don't have to include metadata if you don't want to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WLVasVVM1ceF"
      },
      "outputs": [],
      "source": [
        "document1 = Document(page_content=\"This is my document. It is full of text that I've gathered from other places\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8nRGsnjmos-1"
      },
      "outputs": [],
      "source": [
        "# Prepare the prompt by combining the document content with your custom prompt\n",
        "prompt1 = f\"Document Content: {document1.page_content}\\n\\nPlease summarize the above document.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "i_4SDqdso1Be",
        "outputId": "c4dc8ca3-af9c-46cc-fd7c-9cd3bb81fd97"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The document contains text that the author has collected from various sources.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the response from the language model\n",
        "response = chat.invoke(prompt1)\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-CQSoQo34GT"
      },
      "source": [
        "# **Let's Do an Activity**\n",
        "\n",
        "Create a simple interaction using LangChain and OpenAI's API. Define system, human, and AI messages to simulate a conversation with a travel recommendation bot. Additionally, create a document schema to store information about travel destinations.\n",
        "\n",
        "**Steps**\n",
        "\n",
        "* **Set Up**: Install the necessary libraries and set up your OpenAI API key.\n",
        "* **Define Messages**: Create system, human, and AI messages for a travel bot.\n",
        "* **Simulate Interaction**: Use the chat function to simulate a conversation.\n",
        "* **`Create Document`**: Define a document schema to store information about a travel destination."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft0J5cTOBeqY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
